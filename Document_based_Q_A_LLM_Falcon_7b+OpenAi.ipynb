{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NrgfLZpMIgyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6003174f-e5bc-4130-aba7-f841a9704bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain tiktoken openai pypdf faiss-cpu huggingface_hub python-docx selenium unstructured -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.vectorstores import SKLearnVectorStore\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from docx import Document\n",
        "from langchain.document_loaders import SeleniumURLLoader"
      ],
      "metadata": {
        "id": "EyafiqsoI7Mm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF file. English or French only\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=64,\n",
        "    separators=['\\n\\n', '\\n', '(?=>\\. )', ' ', ''])\n",
        "\n",
        "pdf_doc_path=''\n",
        "if pdf_doc_path:\n",
        "    loader = PyPDFLoader(pdf_doc_path)\n",
        "    pages = loader.load_and_split()\n",
        "\n",
        "txt_path=''\n",
        "if txt_path:\n",
        "    loader=TextLoader(txt_path)\n",
        "    pages=loader.load()\n",
        "\n",
        "docx_path='/content/drive/MyDrive/Data S/data/System engineering.docx'\n",
        "if docx_path:\n",
        "  word_doc=Document(docx_path)\n",
        "  passages=[p.text for p in word_doc.paragraphs]\n",
        "  content = \"\\n\".join(passages)\n",
        "  file_txt_path=\"./file.txt\"\n",
        "  with open(file_txt_path, \"w\") as f:\n",
        "    f.write(content)\n",
        "  loader=TextLoader(file_txt_path)\n",
        "  pages=loader.load()\n",
        "\n",
        "url=['']\n",
        "if url[0]:\n",
        "  loader = SeleniumURLLoader(url)\n",
        "  pages=loader.load()\n",
        "\n",
        "texts = text_splitter.split_documents(pages)\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=\"\")"
      ],
      "metadata": {
        "id": "rURrisgIJTil"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wi-nK8hXiN68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = FAISS.from_documents(texts, embeddings)\n",
        "vector_db.save_local(\"./FAISS_db\", index_name=(\"wiki_rmse\"))"
      ],
      "metadata": {
        "id": "WMF2PY-tEf3u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aHCVxi44nCUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm=HuggingFaceHub(huggingfacehub_api_token=\"\",\n",
        "                    repo_id=\"tiiuae/falcon-7b-instruct\",\n",
        "                    model_kwargs={\"temperature\":0.5 ,\n",
        "                                 \"max_length\":512,\n",
        "                                 \"max_new_tokens\":200\n",
        "                                 })"
      ],
      "metadata": {
        "id": "BaWKCSo84DNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12905a1c-c607-4915-c0fb-8c7d84bad588"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "vector_db=FAISS.load_local(folder_path=\"./FAISS_db\",\n",
        "                           index_name='wiki_rmse',\n",
        "                           embeddings=embeddings)\n",
        "\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
        "                                 retriever=vector_db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "                                 return_source_documents=True,\n",
        "                                 verbose=False\n",
        "                                )\n"
      ],
      "metadata": {
        "id": "ASPbYcmLFCdC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9YLcaAwG-l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask a question?\n",
        "queary='What is system engineering?'\n",
        "results=qa({\"query\": queary})\n"
      ],
      "metadata": {
        "id": "IZ8SS7DWFYLQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results['result'])"
      ],
      "metadata": {
        "id": "i8dQHKVBLm9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cecd4b1-4b56-46cd-8b6d-dce4bb695a04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "System engineering is a methodical, multi-disciplinary approach for the design, realization, technical management, operations, and retirement of a system. A system is the combination of elements that function together to produce the capability required to meet a need. The elements include all hardware, software, equipment, facilities, personnel, processes, and procedures needed for this purpose; that is, all things required to produce system-level results. The results include system-level qualities, properties, characteristics, functions, behavior, and performance. The value added by the system as a whole, beyond that contributed independently by the parts, is primarily created by the relationship among the parts; that is, how they are interconnected.\n"
          ]
        }
      ]
    }
  ]
}